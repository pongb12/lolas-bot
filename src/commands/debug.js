// commands/debug.js
const Config = require('../utils/config');
const Logger = require('../utils/logger');
const ai = require('../ai');
const { EmbedBuilder } = require('discord.js');

module.exports = {
    name: 'debug',
    description: 'ğŸ‘‘ Debug tools for bot owner',
    usage: '.debug <mode>',
    
    async execute(message, args) {
        // Chá»‰ owner má»›i Ä‘Æ°á»£c sá»­ dá»¥ng
        if (message.author.id !== Config.OWNER_ID) {
            const embed = new EmbedBuilder()
                .setColor(0xFF0000)
                .setTitle('âŒ Truy cáº­p bá»‹ tá»« chá»‘i')
                .setDescription('Chá»‰ chá»§ sá»Ÿ há»¯u bot má»›i cÃ³ quyá»n sá»­ dá»¥ng lá»‡nh nÃ y!')
                .setTimestamp();
            
            return message.reply({ embeds: [embed] });
        }
        
        if (args.length === 0) {
            const embed = new EmbedBuilder()
                .setColor(0x0099FF)
                .setTitle('ğŸ‘‘ Owner Debug Menu')
                .setDescription('CÃ´ng cá»¥ debug dÃ nh cho chá»§ bot')
                .addFields(
                    { name: '.debug enable', value: 'Báº­t cháº¿ Ä‘á»™ debug (bypass prompt firewall)' },
                    { name: '.debug disable', value: 'Táº¯t cháº¿ Ä‘á»™ debug' },
                    { name: '.debug stats', value: 'Xem thá»‘ng kÃª báº£o máº­t' },
                    { name: '.debug test <question>', value: 'Test prompt firewall (regex)' },
                    { name: '.debug testml <question>', value: 'Test ML Llama Guard model' },
                    { name: '.debug health', value: 'Xem tráº¡ng thÃ¡i há»‡ thá»‘ng (include ML)' },
                    { name: '.debug mlstats', value: 'Xem thá»‘ng kÃª ML model' },
                    { name: '.debug banned', value: 'Xem danh sÃ¡ch user bá»‹ cháº·n' }
                )
                .setFooter({ text: 'âš ï¸ Cáº©n tháº­n khi test prompt security' })
                .setTimestamp();
            
            return message.reply({ embeds: [embed] });
        }
        
        const subcommand = args[0].toLowerCase();
        
        try {
            switch (subcommand) {
                case 'enable':
                    const enableResult = ai.enableOwnerDebug(message.author.id);
                    await message.reply(`âœ… ${enableResult}`);
                    Logger.warn(`ğŸ‘‘ Owner ${message.author.tag} enabled debug mode`);
                    break;
                    
                case 'disable':
                    const disableResult = ai.disableOwnerDebug(message.author.id);
                    await message.reply(`âœ… ${disableResult}`);
                    Logger.warn(`ğŸ‘‘ Owner ${message.author.tag} disabled debug mode`);
                    break;
                    
                case 'stats':
                    const stats = ai.getSecurityStats(message.author.id);
                    
                    if (typeof stats === 'string') {
                        await message.reply(stats);
                    } else {
                        const embed = new EmbedBuilder()
                            .setColor(0x7289DA)
                            .setTitle('ğŸ›¡ï¸ Security Statistics')
                            .addFields(
                                { name: 'ğŸš« Users Banned', value: stats.bannedUsers.toString(), inline: true },
                                { name: 'ğŸ“Š Recent Attempts', value: stats.recentAttempts.toString(), inline: true },
                                { name: 'âš ï¸ Blocked Attempts', value: stats.blockedAttempts.toString(), inline: true }
                            )
                            .setFooter({ text: 'Lol.AI Security System' })
                            .setTimestamp();
                        
                        await message.reply({ embeds: [embed] });
                    }
                    break;
                    
                case 'test':
                    if (args.length < 2) {
                        return message.reply('âŒ Vui lÃ²ng cung cáº¥p cÃ¢u há»i Ä‘á»ƒ test!');
                    }
                    
                    const testQuestion = args.slice(1).join(' ');
                    const isLeakAttempt = ai.firewall.isPromptLeakAttempt(testQuestion);
                    
                    const resultEmbed = new EmbedBuilder()
                        .setColor(isLeakAttempt ? 0xFF0000 : 0x00FF00)
                        .setTitle('ğŸ” Prompt Firewall Test')
                        .addFields(
                            { name: 'â“ CÃ¢u há»i', value: testQuestion.substring(0, 100) },
                            { name: 'ğŸ›¡ï¸ PhÃ¡t hiá»‡n', value: isLeakAttempt ? 'âš ï¸ **LEAK ATTEMPT DETECTED**' : 'âœ… **SAFE**' },
                            { name: 'ğŸ‘‘ Tráº¡ng thÃ¡i', value: 'Owner - No ban applied' }
                        )
                        .setTimestamp();
                    
                    await message.reply({ embeds: [resultEmbed] });
                    Logger.warn(`ğŸ‘‘ Owner test: "${testQuestion.substring(0, 30)}..." - Detected: ${isLeakAttempt}`);
                    break;
                    
                case 'testml':
                    if (args.length < 2) {
                        return message.reply('âŒ Vui lÃ²ng cung cáº¥p cÃ¢u há»i Ä‘á»ƒ test ML!');
                    }
                    
                    const mlTestQuestion = args.slice(1).join(' ');
                    await message.reply('â³ Äang cháº¡y ML analysis...');
                    
                    try {
                        const mlResult = await ai.testPromptFirewallWithML(message.author.id, mlTestQuestion);
                        
                        const comparisonEmbed = new EmbedBuilder()
                            .setColor(mlResult.comparison.agree ? 0x00FF00 : 0xFFA500)
                            .setTitle('ğŸ¦™ Llama Guard ML Analysis')
                            .addFields(
                                { name: 'â“ Preview', value: mlResult.questionPreview.substring(0, 100), inline: false },
                                { name: 'ğŸ¤– ML Result', value: `${mlResult.ml_analysis.safe ? 'âœ… SAFE' : 'ğŸš« UNSAFE'} (confidence: ${(mlResult.ml_analysis.confidence || 0).toFixed(2)}, source: ${mlResult.ml_analysis.source})`, inline: true },
                                { name: 'ğŸ“‹ Regex Result', value: `${mlResult.regex_analysis.safe ? 'âœ… SAFE' : 'ğŸš« UNSAFE'} (${mlResult.regex_analysis.reason || 'no threat'})`, inline: true },
                                { name: 'ğŸ”„ Agreement', value: mlResult.comparison.agree ? 'âœ… Both agree' : 'âš ï¸ Disagreement detected', inline: false },
                                { name: 'ğŸ’¾ ML Cache', value: mlResult.ml_analysis.cached ? 'âœ… From cache' : 'ğŸ†• Fresh result', inline: true }
                            )
                            .setFooter({ text: 'ML Model: meta-llama/llama-prompt-guard-2-86m' })
                            .setTimestamp();
                        
                        await message.reply({ embeds: [comparisonEmbed] });
                    } catch (e) {
                        Logger.error('ML test error:', e);
                        await message.reply(`âŒ Lá»—i khi test ML: ${e?.message || e}`);
                    }
                    break;
                    
                case 'health':
                    const health = ai.getSystemHealth();
                    const healthEmbed = new EmbedBuilder()
                        .setColor(0x36C5F0)
                        .setTitle('ğŸ’Š System Health Check')
                        .addFields(
                            { name: 'ğŸ“Š AI Statistics', value: `Histories: ${health.ai.histories}\nContexts: ${health.ai.conversationContexts}\nCache: ${health.ai.cache}/${health.config.maxTokens}`, inline: true },
                            { name: 'ğŸ›¡ï¸ Security', value: `Banned: ${health.security.bannedCount}\nAttempts: ${health.security.attemptsCount}\nThreshold: ${health.security.banThreshold}`, inline: true },
                            { name: 'ğŸ¦™ ML Status', value: `Status: ${health.ml.modelInitialized ? 'âœ… Ready' : 'â³ Loading'}\nCache: ${health.ml.cacheSize} entries\nTimeout: ${health.ml.modelTimeout}ms`, inline: true },
                            { name: 'âš™ï¸ Config', value: `Model: ${health.config.model}\nMax Tokens: ${health.config.maxTokens}\nReasoning: ${health.config.reasoningEnabled ? 'âœ…' : 'âŒ'}\nToken Compression: ${health.config.tokenCompressionEnabled ? 'âœ…' : 'âŒ'}`, inline: true },
                            { name: 'â° Uptime', value: `${Math.floor(health.uptime / 3600)}h ${Math.floor((health.uptime % 3600) / 60)}m`, inline: true }
                        )
                        .setFooter({ text: 'Lol.AI v1.6.0 - ML Enhanced' })
                        .setTimestamp();
                    
                    await message.reply({ embeds: [healthEmbed] });
                    break;
                    
                case 'mlstats':
                    const mlStats = ai.firewall.getMLStats();
                    const mlStatsEmbed = new EmbedBuilder()
                        .setColor(0x9370DB)
                        .setTitle('ğŸ¦™ ML Model Statistics')
                        .addFields(
                            { name: 'ğŸ“Œ Status', value: `Initialized: ${mlStats.modelInitialized ? 'âœ… Yes' : 'âŒ No'}\nInitializing: ${mlStats.modelInitializing ? 'ğŸ”„ Yes' : 'âŒ No'}`, inline: true },
                            { name: 'ğŸ’¾ Cache', value: `Size: ${mlStats.cacheSize} entries\nDuration: ${mlStats.cacheDuration}ms (${Math.round(mlStats.cacheDuration / 60000)}m)`, inline: true },
                            { name: 'âš¡ Performance', value: `Init Timeout: ${mlStats.modelTimeout}ms\nMode: ${mlStats.enabled ? 'ğŸŸ¢ ENABLED' : 'ğŸ”´ DISABLED'}`, inline: false }
                        )
                        .setFooter({ text: 'Model: meta-llama/llama-prompt-guard-2-86m (ONNX quantized)' })
                        .setTimestamp();
                    
                    await message.reply({ embeds: [mlStatsEmbed] });
                    break;
                    
                default:
                    // Láº¥y danh sÃ¡ch user bá»‹ cháº·n
                    const bannedList = Array.from(ai.firewall.bannedUsers.entries())
                        .map(([userId, banUntil]) => {
                            const timeLeft = banUntil - Date.now();
                            const hours = Math.floor(timeLeft / 3600000);
                            const minutes = Math.floor((timeLeft % 3600000) / 60000);
                            
                            return `â€¢ <@${userId}> - ${hours}h ${minutes}m cÃ²n láº¡i`;
                        });
                    
                    const embed = new EmbedBuilder()
                        .setColor(0xFFA500)
                        .setTitle('ğŸš« Danh sÃ¡ch user bá»‹ cháº·n')
                        .setDescription(bannedList.length > 0 ? bannedList.join('\n') : 'âœ… KhÃ´ng cÃ³ user nÃ o bá»‹ cháº·n')
                        .addFields(
                            { name: 'Tá»•ng sá»‘', value: bannedList.length.toString() }
                        )
                        .setTimestamp();
                    
                    await message.reply({ embeds: [embed] });
                    break;
                    
                default:
                    await message.reply('âŒ Lá»‡nh debug khÃ´ng há»£p lá»‡. DÃ¹ng `.debug` Ä‘á»ƒ xem menu.');
            }
            
        } catch (error) {
            Logger.error('Lá»—i debug command:', error);
            await message.reply('âŒ ÄÃ£ cÃ³ lá»—i xáº£y ra khi thá»±c thi lá»‡nh debug!');
        }
    }
};
