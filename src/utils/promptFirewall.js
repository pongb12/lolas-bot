const path = require('path');
const fs = require('fs').promises;
const Logger = require('./logger');
const Config = require('./config');

class PromptFirewall {
    constructor() {
        this.classifier = null;
        this.isReady = false;
        
        // 1. Lá»›p lá»c Heuristic (Regex) - Cháº·n cá»±c nhanh cÃ¡c Ä‘Ã²n táº¥n cÃ´ng lá»™ liá»…u
        this.criticalPatterns = [
            /ignore (all )?previous/i,
            /system (prompt|message|instruction)s?/i,
            /hÃ£y in (toÃ n bá»™ )?prompt/i,
            /show (me )?the prompt/i,
            /dÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c luáº­t/i
        ];

        // 2. Danh sÃ¡ch tráº¯ng (Whitelist) - KhÃ´ng bao giá» cháº·n cÃ¡c cÃ¢u nÃ y
        this.whitelist = [
            /mÃ¡y bay/i, /thá»i tiáº¿t/i, /náº¥u Äƒn/i, /há»c táº­p/i
        ];

        this.attempts = new Map();
        this.bannedUsers = new Map();
        this.BAN_THRESHOLD = Config.BAN_THRESHOLD || 5;
        this.BAN_DURATION = Config.BAN_DURATION || 86400000;

        // Khá»Ÿi táº¡o AI
        this.initAI();
    }

    async initAI() {
        try {
            // Import Ä‘á»™ng Ä‘á»ƒ tiáº¿t kiá»‡m RAM khi khá»Ÿi Ä‘á»™ng
            const { pipeline, env } = await import('@xenova/transformers');
            
            // Cáº¥u hÃ¬nh Ä‘á»ƒ cháº¡y mÆ°á»£t trÃªn mÃ´i trÆ°á»ng server
            env.allowLocalModels = false;
            env.useBrowserCache = false;

            this.classifier = await pipeline('text-classification', 'Xenova/llama-prompt-guard-2-86m');
            this.isReady = true;
            Logger.success('ðŸ§  PromptFirewall: AI Model Loaded (Llama-86M)');
        } catch (e) {
            Logger.error('ðŸ§  PromptFirewall: AI Load Failed: ' + e.message);
        }
    }

    /* ================= PHÃ‚N TÃCH Ná»˜I DUNG ================= */
    async analyzeContent(text) {
        if (!text || typeof text !== 'string') return { safe: true };

        const lowerText = text.toLowerCase();

        // Æ¯u tiÃªn 1: Check Whitelist (TrÃ¡nh cháº·n nháº§m "mÃ¡y bay")
        if (this.whitelist.some(p => p.test(lowerText))) {
            return { safe: true, reason: 'whitelist' };
        }

        // Æ¯u tiÃªn 2: Check Regex Critical (Táº¥n cÃ´ng quÃ¡ rÃµ rÃ ng)
        if (this.criticalPatterns.some(p => p.test(lowerText))) {
            return { safe: false, reason: 'critical_regex', confidence: 1.0 };
        }

        // Æ¯u tiÃªn 3: DÃ¹ng AI Ä‘á»ƒ phÃ¢n tÃ­ch ngá»¯ cáº£nh (PhÃ¢n biá»‡t há»i cáº¥u táº¡o mÃ¡y bay vs cáº¥u táº¡o prompt)
        if (this.isReady) {
            try {
                const results = await this.classifier(text);
                // Model tráº£ vá» nhÃ£n 'INJECTION' hoáº·c 'JAILBREAK' náº¿u nguy hiá»ƒm
                const isAttack = results[0].label !== 'BENIGN';
                const score = results[0].score;

                if (isAttack && score > 0.85) { // Chá»‰ cháº·n khi AI cháº¯c cháº¯n trÃªn 85%
                    return { safe: false, reason: 'ai_detected', confidence: score };
                }
            } catch (err) {
                Logger.error('AI Analysis Error: ' + err.message);
            }
        }

        return { safe: true };
    }

    /* ================= THEO DÃ•I & CHáº¶N ================= */
    async trackAttempt(userId, question) {
        // Owner Immunity
        if (userId === Config.OWNER_ID) return { allowed: true };
        
        // Kiá»ƒm tra ban
        if (this.isBanned(userId)) return { allowed: false, reason: 'banned' };

        const analysis = await this.analyzeContent(question);

        if (!analysis.safe) {
            Logger.warn(`ðŸš¨ Security: User ${userId} triggered ${analysis.reason} (${analysis.confidence})`);
            
            const now = Date.now();
            const userAttempts = this.attempts.get(userId) || [];
            const recentAttempts = userAttempts.filter(t => now - t < 600000); // 10 phÃºt
            
            recentAttempts.push(now);
            this.attempts.set(userId, recentAttempts);

            if (recentAttempts.length >= this.BAN_THRESHOLD) {
                this.banUser(userId);
                return { allowed: false, reason: 'banned' };
            }

            return { allowed: false, reason: 'warning' };
        }

        return { allowed: true };
    }

    banUser(userId) {
        const banUntil = Date.now() + this.BAN_DURATION;
        this.bannedUsers.set(userId, banUntil);
        Logger.error(`ðŸš« User ${userId} has been banned for 24h due to prompt injection attempts.`);
    }

    isBanned(userId) {
        const banUntil = this.bannedUsers.get(userId);
        if (!banUntil) return false;
        if (Date.now() > banUntil) {
            this.bannedUsers.delete(userId);
            return false;
        }
        return true;
    }
}

module.exports = new PromptFirewall();
